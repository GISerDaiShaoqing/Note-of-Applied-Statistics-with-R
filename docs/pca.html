<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第 12 章 Priciple Component Analysis | 应用统计学与R语言实现学习笔记</title>
  <meta name="description" content="第 12 章 Priciple Component Analysis | 应用统计学与R语言实现学习笔记" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="第 12 章 Priciple Component Analysis | 应用统计学与R语言实现学习笔记" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.jpg" />
  
  <meta name="github-repo" content="GISerDaiShaoqing/Note-of-Applied-Statistics-with-R-Book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第 12 章 Priciple Component Analysis | 应用统计学与R语言实现学习笔记" />
  
  
  <meta name="twitter:image" content="images/cover.jpg" />

<meta name="author" content="戴劭勍" />


<meta name="date" content="2021-03-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="discriminant.html"/>
<link rel="next" href="fa.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.3/leaflet.js"></script>
<script src="libs/leaflet-providers-1.9.0/leaflet-providers_1.9.0.js"></script>
<script src="libs/leaflet-providers-plugin-2.0.3/leaflet-providers-plugin.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">中文书示例</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#致谢"><i class="fa fa-check"></i>致谢</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i>作者简介</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#从问题说起"><i class="fa fa-check"></i><b>1.1</b> 从问题说起</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#统计学及其研究过程"><i class="fa fa-check"></i><b>1.2</b> 统计学及其研究过程</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#统计方法及其应用领域"><i class="fa fa-check"></i><b>1.3</b> 统计方法及其应用领域</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#统计数据类型"><i class="fa fa-check"></i><b>1.4</b> 统计数据类型</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#统计学中的几个基本概念"><i class="fa fa-check"></i><b>1.5</b> 统计学中的几个基本概念</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="datacollec.html"><a href="datacollec.html"><i class="fa fa-check"></i><b>2</b> Data Collection</a><ul>
<li class="chapter" data-level="2.1" data-path="datacollec.html"><a href="datacollec.html#数据来源"><i class="fa fa-check"></i><b>2.1</b> 数据来源</a></li>
<li class="chapter" data-level="2.2" data-path="datacollec.html"><a href="datacollec.html#调查设计"><i class="fa fa-check"></i><b>2.2</b> 调查设计</a></li>
<li class="chapter" data-level="2.3" data-path="datacollec.html"><a href="datacollec.html#数据质量"><i class="fa fa-check"></i><b>2.3</b> 数据质量</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="descriptive.html"><a href="descriptive.html"><i class="fa fa-check"></i><b>3</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="3.1" data-path="descriptive.html"><a href="descriptive.html#数据的预处理"><i class="fa fa-check"></i><b>3.1</b> 数据的预处理</a></li>
<li class="chapter" data-level="3.2" data-path="descriptive.html"><a href="descriptive.html#数据的整理与展示"><i class="fa fa-check"></i><b>3.2</b> 数据的整理与展示</a></li>
<li class="chapter" data-level="3.3" data-path="descriptive.html"><a href="descriptive.html#数据的概括性度量"><i class="fa fa-check"></i><b>3.3</b> 数据的概括性度量</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>4</b> Sampling And Sample Distribution</a><ul>
<li class="chapter" data-level="4.1" data-path="sampling.html"><a href="sampling.html#抽样方法"><i class="fa fa-check"></i><b>4.1</b> 抽样方法</a></li>
<li class="chapter" data-level="4.2" data-path="sampling.html"><a href="sampling.html#正态分布"><i class="fa fa-check"></i><b>4.2</b> 正态分布</a></li>
<li class="chapter" data-level="4.3" data-path="sampling.html"><a href="sampling.html#三种不同性质的分布"><i class="fa fa-check"></i><b>4.3</b> 三种不同性质的分布</a></li>
<li class="chapter" data-level="4.4" data-path="sampling.html"><a href="sampling.html#一个总体样本统计量的抽样分布"><i class="fa fa-check"></i><b>4.4</b> 一个总体样本统计量的抽样分布</a></li>
<li class="chapter" data-level="4.5" data-path="sampling.html"><a href="sampling.html#两个总体样本统计量的抽样分布"><i class="fa fa-check"></i><b>4.5</b> 两个总体样本统计量的抽样分布</a></li>
<li class="chapter" data-level="4.6" data-path="sampling.html"><a href="sampling.html#附录"><i class="fa fa-check"></i><b>4.6</b> 附录</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>5</b> Estimation</a><ul>
<li class="chapter" data-level="5.1" data-path="estimation.html"><a href="estimation.html#参数估计的一般问题"><i class="fa fa-check"></i><b>5.1</b> 参数估计的一般问题</a></li>
<li class="chapter" data-level="5.2" data-path="estimation.html"><a href="estimation.html#区间估计-confidence-intervals"><i class="fa fa-check"></i><b>5.2</b> 区间估计 Confidence Intervals</a></li>
<li class="chapter" data-level="5.3" data-path="estimation.html"><a href="estimation.html#样本容量的确定"><i class="fa fa-check"></i><b>5.3</b> 样本容量的确定</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypothesis.html"><a href="hypothesis.html"><i class="fa fa-check"></i><b>6</b> Hypothesis Test</a><ul>
<li class="chapter" data-level="6.1" data-path="hypothesis.html"><a href="hypothesis.html#基本思想"><i class="fa fa-check"></i><b>6.1</b> 基本思想</a></li>
<li class="chapter" data-level="6.2" data-path="hypothesis.html"><a href="hypothesis.html#原假设和备择假设"><i class="fa fa-check"></i><b>6.2</b> 原假设和备择假设</a></li>
<li class="chapter" data-level="6.3" data-path="hypothesis.html"><a href="hypothesis.html#第一类错误和第二类错误"><i class="fa fa-check"></i><b>6.3</b> 第一类错误和第二类错误</a></li>
<li class="chapter" data-level="6.4" data-path="hypothesis.html"><a href="hypothesis.html#统计量与拒绝域"><i class="fa fa-check"></i><b>6.4</b> 统计量与拒绝域</a></li>
<li class="chapter" data-level="6.5" data-path="hypothesis.html"><a href="hypothesis.html#利用p值进行决策"><i class="fa fa-check"></i><b>6.5</b> 利用p值进行决策</a></li>
<li class="chapter" data-level="6.6" data-path="hypothesis.html"><a href="hypothesis.html#一个总体参数的检验"><i class="fa fa-check"></i><b>6.6</b> 一个总体参数的检验</a></li>
<li class="chapter" data-level="6.7" data-path="hypothesis.html"><a href="hypothesis.html#两个总体参数的检验"><i class="fa fa-check"></i><b>6.7</b> 两个总体参数的检验</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="goodness.html"><a href="goodness.html"><i class="fa fa-check"></i><b>7</b> Goodness of Fit</a><ul>
<li class="chapter" data-level="7.1" data-path="goodness.html"><a href="goodness.html#多项分布"><i class="fa fa-check"></i><b>7.1</b> 多项分布</a></li>
<li class="chapter" data-level="7.2" data-path="goodness.html"><a href="goodness.html#独立性"><i class="fa fa-check"></i><b>7.2</b> 独立性</a></li>
<li class="chapter" data-level="7.3" data-path="goodness.html"><a href="goodness.html#概率分布"><i class="fa fa-check"></i><b>7.3</b> 概率分布</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ANOVA.html"><a href="ANOVA.html"><i class="fa fa-check"></i><b>8</b> ANOVA</a><ul>
<li class="chapter" data-level="8.1" data-path="ANOVA.html"><a href="ANOVA.html#方差分析的引论"><i class="fa fa-check"></i><b>8.1</b> 方差分析的引论</a><ul>
<li class="chapter" data-level="8.1.1" data-path="ANOVA.html"><a href="ANOVA.html#方差分析的部分概念"><i class="fa fa-check"></i><b>8.1.1</b> 方差分析的部分概念</a></li>
<li class="chapter" data-level="8.1.2" data-path="ANOVA.html"><a href="ANOVA.html#方差分析的基本思想和原理"><i class="fa fa-check"></i><b>8.1.2</b> 方差分析的基本思想和原理</a></li>
<li class="chapter" data-level="8.1.3" data-path="ANOVA.html"><a href="ANOVA.html#方差分析的基本假定"><i class="fa fa-check"></i><b>8.1.3</b> 方差分析的基本假定</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ANOVA.html"><a href="ANOVA.html#单因子方差分析one-way-anova"><i class="fa fa-check"></i><b>8.2</b> 单因子方差分析（One-way ANOVA)</a></li>
<li class="chapter" data-level="8.3" data-path="ANOVA.html"><a href="ANOVA.html#方差分析中的多重比较"><i class="fa fa-check"></i><b>8.3</b> 方差分析中的多重比较</a></li>
<li class="chapter" data-level="8.4" data-path="ANOVA.html"><a href="ANOVA.html#双因子方差分析two-way-anova"><i class="fa fa-check"></i><b>8.4</b> 双因子方差分析（Two-way ANOVA）</a><ul>
<li class="chapter" data-level="8.4.1" data-path="ANOVA.html"><a href="ANOVA.html#双因子方差分析的基本假定"><i class="fa fa-check"></i><b>8.4.1</b> 双因子方差分析的基本假定</a></li>
<li class="chapter" data-level="8.4.2" data-path="ANOVA.html"><a href="ANOVA.html#无交互作用双因子方差分析"><i class="fa fa-check"></i><b>8.4.2</b> 无交互作用双因子方差分析</a></li>
<li class="chapter" data-level="8.4.3" data-path="ANOVA.html"><a href="ANOVA.html#有交互作用双因子方差分析"><i class="fa fa-check"></i><b>8.4.3</b> 有交互作用双因子方差分析</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ANOVA.html"><a href="ANOVA.html#实验设计初步"><i class="fa fa-check"></i><b>8.5</b> 实验设计初步</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>9</b> Linear Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="regression.html"><a href="regression.html#变量间的关系"><i class="fa fa-check"></i><b>9.1</b> 变量间的关系</a></li>
<li class="chapter" data-level="9.2" data-path="regression.html"><a href="regression.html#回归分析和简单线性回归分析"><i class="fa fa-check"></i><b>9.2</b> 回归分析和简单线性回归分析</a><ul>
<li class="chapter" data-level="9.2.1" data-path="regression.html"><a href="regression.html#回归分析"><i class="fa fa-check"></i><b>9.2.1</b> 回归分析</a></li>
<li class="chapter" data-level="9.2.2" data-path="regression.html"><a href="regression.html#简单线性回归分析"><i class="fa fa-check"></i><b>9.2.2</b> 简单线性回归分析</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="regression.html"><a href="regression.html#利用回归方程进行估计和预测"><i class="fa fa-check"></i><b>9.3</b> 利用回归方程进行估计和预测</a></li>
<li class="chapter" data-level="9.4" data-path="regression.html"><a href="regression.html#残差分析"><i class="fa fa-check"></i><b>9.4</b> 残差分析</a></li>
<li class="chapter" data-level="9.5" data-path="regression.html"><a href="regression.html#多元线性回归multiple-regression-model"><i class="fa fa-check"></i><b>9.5</b> 多元线性回归(multiple regression model)</a></li>
<li class="chapter" data-level="9.6" data-path="regression.html"><a href="regression.html#定性自变量的回归"><i class="fa fa-check"></i><b>9.6</b> 定性自变量的回归</a></li>
<li class="chapter" data-level="9.7" data-path="regression.html"><a href="regression.html#非线性回归"><i class="fa fa-check"></i><b>9.7</b> 非线性回归</a></li>
<li class="chapter" data-level="9.8" data-path="regression.html"><a href="regression.html#建立回归模型"><i class="fa fa-check"></i><b>9.8</b> 建立回归模型</a></li>
<li class="chapter" data-level="9.9" data-path="regression.html"><a href="regression.html#回归中的常见错误"><i class="fa fa-check"></i><b>9.9</b> 回归中的常见错误</a></li>
<li class="chapter" data-level="9.10" data-path="regression.html"><a href="regression.html#logistic-回归"><i class="fa fa-check"></i><b>9.10</b> Logistic 回归</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="cluster.html"><a href="cluster.html"><i class="fa fa-check"></i><b>10</b> Cluster Analysis</a><ul>
<li class="chapter" data-level="10.1" data-path="cluster.html"><a href="cluster.html#多元分布基本概念"><i class="fa fa-check"></i><b>10.1</b> 多元分布基本概念</a></li>
<li class="chapter" data-level="10.2" data-path="cluster.html"><a href="cluster.html#数据的变换处理"><i class="fa fa-check"></i><b>10.2</b> 数据的变换处理</a></li>
<li class="chapter" data-level="10.3" data-path="cluster.html"><a href="cluster.html#聚类分析"><i class="fa fa-check"></i><b>10.3</b> 聚类分析</a></li>
<li class="chapter" data-level="10.4" data-path="cluster.html"><a href="cluster.html#样品间亲疏程度的测度"><i class="fa fa-check"></i><b>10.4</b> 样品间亲疏程度的测度</a></li>
<li class="chapter" data-level="10.5" data-path="cluster.html"><a href="cluster.html#类与类之间的距离"><i class="fa fa-check"></i><b>10.5</b> 类与类之间的距离</a></li>
<li class="chapter" data-level="10.6" data-path="cluster.html"><a href="cluster.html#系统聚类hierarchical-clustering-method"><i class="fa fa-check"></i><b>10.6</b> 系统聚类(hierarchical clustering method)</a></li>
<li class="chapter" data-level="10.7" data-path="cluster.html"><a href="cluster.html#快速聚类k-means-clustering-method"><i class="fa fa-check"></i><b>10.7</b> 快速聚类(k-means clustering method)</a></li>
<li class="chapter" data-level="10.8" data-path="cluster.html"><a href="cluster.html#有序聚类"><i class="fa fa-check"></i><b>10.8</b> 有序聚类</a></li>
<li class="chapter" data-level="10.9" data-path="cluster.html"><a href="cluster.html#聚类分析的主要步骤"><i class="fa fa-check"></i><b>10.9</b> 聚类分析的主要步骤</a></li>
<li class="chapter" data-level="10.10" data-path="cluster.html"><a href="cluster.html#r语言中聚类分析实现"><i class="fa fa-check"></i><b>10.10</b> R语言中聚类分析实现</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="discriminant.html"><a href="discriminant.html"><i class="fa fa-check"></i><b>11</b> Discriminant Analysis</a><ul>
<li class="chapter" data-level="11.1" data-path="discriminant.html"><a href="discriminant.html#判别分析应用"><i class="fa fa-check"></i><b>11.1</b> 判别分析应用</a></li>
<li class="chapter" data-level="11.2" data-path="discriminant.html"><a href="discriminant.html#判别分析方法"><i class="fa fa-check"></i><b>11.2</b> 判别分析方法</a><ul>
<li class="chapter" data-level="11.2.1" data-path="discriminant.html"><a href="discriminant.html#距离判别法"><i class="fa fa-check"></i><b>11.2.1</b> 距离判别法</a></li>
<li class="chapter" data-level="11.2.2" data-path="discriminant.html"><a href="discriminant.html#fisher判别法"><i class="fa fa-check"></i><b>11.2.2</b> Fisher判别法</a></li>
<li class="chapter" data-level="11.2.3" data-path="discriminant.html"><a href="discriminant.html#bayes判别法"><i class="fa fa-check"></i><b>11.2.3</b> Bayes判别法</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="discriminant.html"><a href="discriminant.html#建立判别函数的方法"><i class="fa fa-check"></i><b>11.3</b> 建立判别函数的方法</a></li>
<li class="chapter" data-level="11.4" data-path="discriminant.html"><a href="discriminant.html#判别分析的步骤及注意事项"><i class="fa fa-check"></i><b>11.4</b> 判别分析的步骤及注意事项</a></li>
<li class="chapter" data-level="11.5" data-path="discriminant.html"><a href="discriminant.html#r语言中判别分析实现"><i class="fa fa-check"></i><b>11.5</b> R语言中判别分析实现</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>12</b> Priciple Component Analysis</a><ul>
<li class="chapter" data-level="12.1" data-path="pca.html"><a href="pca.html#主成分分析基本思想"><i class="fa fa-check"></i><b>12.1</b> 主成分分析基本思想</a></li>
<li class="chapter" data-level="12.2" data-path="pca.html"><a href="pca.html#几何解释与数学模型"><i class="fa fa-check"></i><b>12.2</b> 几何解释与数学模型</a><ul>
<li class="chapter" data-level="12.2.1" data-path="pca.html"><a href="pca.html#几何解释"><i class="fa fa-check"></i><b>12.2.1</b> 几何解释</a></li>
<li class="chapter" data-level="12.2.2" data-path="pca.html"><a href="pca.html#数学模型"><i class="fa fa-check"></i><b>12.2.2</b> 数学模型</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="pca.html"><a href="pca.html#主成分的推导"><i class="fa fa-check"></i><b>12.3</b> 主成分的推导</a></li>
<li class="chapter" data-level="12.4" data-path="pca.html"><a href="pca.html#主成分的性质"><i class="fa fa-check"></i><b>12.4</b> 主成分的性质</a></li>
<li class="chapter" data-level="12.5" data-path="pca.html"><a href="pca.html#主成分分析的步骤"><i class="fa fa-check"></i><b>12.5</b> 主成分分析的步骤</a></li>
<li class="chapter" data-level="12.6" data-path="pca.html"><a href="pca.html#主成分的应用与回归"><i class="fa fa-check"></i><b>12.6</b> 主成分的应用与回归</a></li>
<li class="chapter" data-level="12.7" data-path="pca.html"><a href="pca.html#主成分分析的r语言实现"><i class="fa fa-check"></i><b>12.7</b> 主成分分析的R语言实现</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="fa.html"><a href="fa.html"><i class="fa fa-check"></i><b>13</b> Factor Analysis</a><ul>
<li class="chapter" data-level="13.1" data-path="fa.html"><a href="fa.html#因子分析概念"><i class="fa fa-check"></i><b>13.1</b> 因子分析概念</a></li>
<li class="chapter" data-level="13.2" data-path="fa.html"><a href="fa.html#因子分析模型"><i class="fa fa-check"></i><b>13.2</b> 因子分析模型</a></li>
<li class="chapter" data-level="13.3" data-path="fa.html"><a href="fa.html#因子载荷矩阵的估计方法"><i class="fa fa-check"></i><b>13.3</b> 因子载荷矩阵的估计方法</a></li>
<li class="chapter" data-level="13.4" data-path="fa.html"><a href="fa.html#因子旋转正交变换"><i class="fa fa-check"></i><b>13.4</b> 因子旋转（正交变换）</a></li>
<li class="chapter" data-level="13.5" data-path="fa.html"><a href="fa.html#因子得分"><i class="fa fa-check"></i><b>13.5</b> 因子得分</a></li>
<li class="chapter" data-level="13.6" data-path="fa.html"><a href="fa.html#因子分析步骤"><i class="fa fa-check"></i><b>13.6</b> 因子分析步骤</a></li>
<li class="chapter" data-level="13.7" data-path="fa.html"><a href="fa.html#因子分析的r语言实现"><i class="fa fa-check"></i><b>13.7</b> 因子分析的R语言实现</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="homework.html"><a href="homework.html"><i class="fa fa-check"></i><b>14</b> Case and Practice</a><ul>
<li class="chapter" data-level="14.1" data-path="homework.html"><a href="homework.html#描述性统计与抽样分布"><i class="fa fa-check"></i><b>14.1</b> 描述性统计与抽样分布</a></li>
<li class="chapter" data-level="14.2" data-path="homework.html"><a href="homework.html#参数估计与假设检验"><i class="fa fa-check"></i><b>14.2</b> 参数估计与假设检验</a></li>
<li class="chapter" data-level="14.3" data-path="homework.html"><a href="homework.html#方差分析与回归分析"><i class="fa fa-check"></i><b>14.3</b> 方差分析与回归分析</a></li>
<li class="chapter" data-level="14.4" data-path="homework.html"><a href="homework.html#作业文档"><i class="fa fa-check"></i><b>14.4</b> 作业文档</a><ul>
<li class="chapter" data-level="14.4.1" data-path="homework.html"><a href="homework.html#描述性统计与抽样分布-1"><i class="fa fa-check"></i><b>14.4.1</b> 1 描述性统计与抽样分布</a></li>
<li class="chapter" data-level="14.4.2" data-path="homework.html"><a href="homework.html#参数估计与假设检验-1"><i class="fa fa-check"></i><b>14.4.2</b> 2 参数估计与假设检验</a></li>
<li class="chapter" data-level="14.4.3" data-path="homework.html"><a href="homework.html#方差分析与回归分析-1"><i class="fa fa-check"></i><b>14.4.3</b> 3 方差分析与回归分析</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>参考文献</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">本书由 bookdown 强力驱动</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">应用统计学与R语言实现学习笔记</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pca" class="section level1">
<h1><span class="header-section-number">第 12 章</span> Priciple Component Analysis</h1>
<p>本篇是第十二章，内容是主成分分析。</p>
<div id="主成分分析基本思想" class="section level2">
<h2><span class="header-section-number">12.1</span> 主成分分析基本思想</h2>
<p>依旧从问题开始本篇的介绍。地理学和生态学研究里经常遇到的问题就是，影响变量非常之多，而且地球表层地理生态环境现象无法使用控制变量的方式进行实验。同时影响变量非常多，经常出现变量冗余、冗杂的现象，同时多元分布数据本身对人类的认知就是一种挑战。这里举个栗子：比如在研究城市经济发展的时候，我们会考虑到的因素会包括第一产业、第二产业、第三产业占比，城市人口，城市地理位置，城市气候适宜度，政策扶持等等很多因子，但是这里有很多因子存在共线性的情况，也就是变量冗余冗杂。用矛盾论的话说，要抓住主要矛盾，那么如何在多元分布数据中分离出主要的因子，这就是本篇的主角主成分分析（Priciple Component Analysis，PCA）。</p>
<p>所以它的<strong>基本思想</strong>是，在社会经济的研究中，为了全面系统的分析和研究问题，必须考虑许多经济指标，这些指标能从不同的侧面反映我们所研究的对象的特征，但在某种程度上存在信息的重叠，具有一定的相关性。这种信息的重叠有时甚至会抹杀事物的真正特征与内在规律。</p>
<p>主成分分析是利用降维的思想， 在力求数据信息丢失最少的原则下，对高维的变量空间降维，即在众多变量中找出少数几个综合指标（原始变量的线性组合），并且这几个综合指标将尽可能多地保留原来指标变异方面的信息，且这些综合指标互不相关。这些综合指标就称为主成分。主成分的数目少于原始变量的数目。</p>
<p>在一个低维空间识辨系统要比在一个高维空间容易得多。因此，更容易抓住主要矛盾，揭示事物内部变量之间的规律性，使问题得到简化，提高分析效率。指标间具有相关性是做主成分分析的前提。</p>
<p>主成分分析是一种数学变换方法，它把给定的一组变量通过线性变换转换为一组不相关的变量。在这种变换中，保持变量的总方差不变，同时，使第一主成分具有最大方差，第二主成分具有次大方差，依此类推。</p>
<p><strong>主成分与原始变量间的关系</strong></p>
<p>（1）每一个主成分是原始变量的线性组合。</p>
<p>（2）主成分的数目少于原始变量的数目。</p>
<p>（3）主成分保留了原始变量的大多数变异信息。</p>
<p>（4）各主成分间互不相关。</p>
</div>
<div id="几何解释与数学模型" class="section level2">
<h2><span class="header-section-number">12.2</span> 几何解释与数学模型</h2>
<div id="几何解释" class="section level3">
<h3><span class="header-section-number">12.2.1</span> 几何解释</h3>
<p>假定只有二维，即只有两个变量，由横坐标和纵坐标所代表；每个观测值都有相应于这两个坐标轴的坐标值。如果这些数据形成一个椭圆形状的点阵（这在二维正态的假定下是可能的）该椭圆有一个长轴和一个短轴。在短轴方向上数据变化较少。在极端的情况，短轴如退化成一点，长轴的方向可以完全解释这些点的变化，由二维到一维的降维就自然完成了。</p>
<p><img src="fig/pca.jpg" width="100%" height="50%" /></p>
<p>由图可以看出这些样本点无论是沿着<span class="math inline">\(x_l\)</span>轴方向或<span class="math inline">\(x_2\)</span>轴方向都具有较大的离散性，其离散的程度可以分别用观测变量<span class="math inline">\(x_l\)</span>的方差和<span class="math inline">\(x_2\)</span>的方差定量地表示。显然，如果只考虑<span class="math inline">\(x_1\)</span>和<span class="math inline">\(x_2\)</span>中的任何一个，那么包含在原始数据中的经济信息将会有较大的损失。</p>
<p>当坐标轴和椭圆的长短轴平行，那么代表长轴的变量就描述了数据的主要变化，而代表短轴的变量就描述了数据的次要变化。但是，坐标轴通常并不和椭圆的长短轴平行。因此，需要寻找椭圆的长短轴，并进行变换，使得新变量和椭圆的长短轴平行。如果长轴变量代表了数据包含的大部分信息，就用该变量代替原先的两个变量（舍去次要的一维），降维就完成了。椭圆的长短轴相差得越大，降维也越有道理。</p>
</div>
<div id="数学模型" class="section level3">
<h3><span class="header-section-number">12.2.2</span> 数学模型</h3>
<p>如果我们将xl轴和x2轴先平移，再同时按逆时针方向旋转<span class="math inline">\(\theta\)</span>角度，得到新坐标轴Fl和F2。Fl和F2是两个新变量。根据旋转变换的公式：</p>
<p><span class="math display">\[\begin{cases} y_1=x_1\cos\theta+x_2\sin\theta \\ y_2=-x_1\sin\theta+x_2\cos\theta \end{cases}\]</span></p>
<p><span class="math display">\[\begin{pmatrix} y_1 \\ y_2 \end{pmatrix}=\begin{pmatrix} \cos\theta &amp; \sin\theta \\ -\sin\theta &amp; \cos\theta \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}=U&#39;x\]</span></p>
<p><span class="math inline">\(U&#39;\)</span>为旋转变换矩阵，它是正交矩阵，即有<span class="math inline">\(U&#39;=U^{-1},U&#39;U^{-1}=I\)</span>。旋转变换的目的是为了使得n个样品点在<span class="math inline">\(F_l\)</span>轴方向上的离散程度最大，即<span class="math inline">\(F_l\)</span>的方差最大。变量<span class="math inline">\(F_l\)</span>代表了原始数据的绝大部分信息，在研究某经济问题时，即使不考虑变量<span class="math inline">\(F_2\)</span>也无损大局。经过上述旋转变换原始数据的大部分信息集中到<span class="math inline">\(F_l\)</span>轴上，对数据中包含的信息起到了浓缩作用。<span class="math inline">\(F_l\)</span>， <span class="math inline">\(F_2\)</span>除了可以对包含在<span class="math inline">\(X_l\)</span>，<span class="math inline">\(X_2\)</span>中的信息起着浓缩作用之外，还具有不相关的性质，这就使得在研究复杂的问题时避免了信息重叠所带来的虚假性。二维平面上的个点的方差大部分都归结在<span class="math inline">\(F_l\)</span>轴上，而<span class="math inline">\(F_2\)</span>轴上的方差很小。 <span class="math inline">\(F_l\)</span>和<span class="math inline">\(F_2\)</span>称为原始变量，<span class="math inline">\(x_1\)</span>和<span class="math inline">\(x_2\)</span>的综合变量。 简化了系统结构，抓住了主要矛盾。</p>
<p><strong>多维情形</strong></p>
<p>多维变量的情况和二维类似。正如二维椭圆有两个主轴，三维椭球有三个主轴一样，有几个变量，就有几个主轴。和二维情况类似，高维椭球的主轴也是互相垂直的。首先把高维椭球的主轴找出来，再用代表大多数数据信息的最长的几个轴作为新变量。这些互相正交的新变量是原先变量的线性组合，叫做主成分(principal component)。</p>
<p>假设我们所讨论的实际问题中，有p个指标，我们把这p个指标看作p个随机变量，记为<span class="math inline">\(X_1,X_2,\cdots,X_p\)</span>，主成分分析就是要把这个p指标的问题，转变为讨论p个指标的线性组合的问题，而这些新的指标<span class="math inline">\(F_1,F_2,\cdots,F_k(k\le p)\)</span>，按照保留主要信息量的原则充分反映原指标的信息，并且相互独立。</p>
<p>这种由讨论多个指标降为少数几个综合指标的过程在数学上就叫做降维。主成分分析通常的做法是，寻求原指标的线性组合Fi。
<span class="math display">\[F_1=u_{11}X_1+u_{21}X_2+\cdots+u_{p1}X_p\]</span></p>
<p><span class="math display">\[F_2=u_{12}X_1+u_{22}X_2+\cdots+u_{p2}X_p\]</span></p>
<p><span class="math display">\[\cdots\]</span></p>
<p><span class="math display">\[F_p=u_{1p}X_1+u_{2p}X_2+\cdots+u_{pp}X_p\]</span></p>
<p><strong>满足条件</strong></p>
<p>每个主成分的系数平方和为1。即<span class="math inline">\(u_{1i}^2+u_{2i}^2+\cdots+u_{pi}^2=1\)</span>，主成分之间相互独立，即无重叠的信息。即<span class="math inline">\(Cov(F_i,F_j)=0,i\neq j,i,j=1,2,\cdots,p\)</span>。主成分的方差依次递减，重要性依次递减，即<span class="math display">\[Var(F_1)\ge Var(F_2)\ge \cdots \ge Var(F_p)\]</span></p>
</div>
</div>
<div id="主成分的推导" class="section level2">
<h2><span class="header-section-number">12.3</span> 主成分的推导</h2>
<p><strong>两个线性代数的结论</strong></p>
<p>（1）若A是p阶实对称矩阵，则一定可以找到正交阵U，使</p>
<p><span class="math display">\[U^{-1}AU=\begin{bmatrix} \lambda_1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; \lambda_2 &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; \lambda_p \end{bmatrix}_{p\times p}\]</span></p>
<p>其中<span class="math inline">\(\lambda_i,i=1,2,\cdots,p\)</span>是A的特征根。</p>
<p>（1）若上述矩阵的特征根所对应的单位特征向量为<span class="math inline">\(u_1,\cdots,u_p\)</span>。令<span class="math inline">\(U=(u_1,\cdots,u_p)=\begin {bmatrix} u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1p} \\ u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2p} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ u_{p1} &amp; u_{p2} &amp; \cdots &amp; u_{pp} \end {bmatrix}\)</span>则实对称阵A属于不同特征根所对应的特征向量是正交的，即有<span class="math inline">\(U&#39;U=UU&#39;=I\)</span></p>
<p><strong>第一主成分</strong></p>
<p>设X的协方差阵为<span class="math inline">\(\Sigma_x=\begin {bmatrix} \sigma_{11} &amp; \sigma_{12} &amp; \cdots &amp; \sigma_{1p} \\ \sigma_{21} &amp; \sigma_{22} &amp; \cdots &amp; \sigma_{2p} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ \sigma_{p1} &amp; \sigma_{p2} &amp; \cdots &amp; \sigma_{pp} \end {bmatrix}\)</span>。由于<span class="math inline">\(\Sigma_x\)</span>为非负定的对称阵，必存在正交阵U，使得：</p>
<p><span class="math display">\[U&#39;\Sigma_x U=\begin {bmatrix} \lambda_1 &amp; &amp; 0 \\  &amp; \ddots  &amp; \\ 0 &amp; &amp; \lambda_p \end {bmatrix}\]</span></p>
<p>其中<span class="math inline">\(\lambda_1,\lambda_2,\cdots,\lambda_p\)</span>为<span class="math inline">\(\Sigma_x\)</span>的特征根。</p>
<p>不妨假设<span class="math inline">\(\lambda_1\ge \lambda_2\ge \cdots \ge \lambda_p\)</span>。而U恰好是由特征根相对应的特征向量所组成的正交阵。</p>
<p><span class="math display">\[U=(u_1,\cdots,u_p)=\begin {bmatrix} u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1p} \\ u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2p} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ u_{p1} &amp; u_{p2} &amp; \cdots &amp; u_{pp} \end {bmatrix}\]</span></p>
<p><span class="math display">\[U_i=(u_{1i},u_{2i},\cdots,u_{pi})&#39; i=1,2,\cdots,p\]</span></p>
<p>设有p维正交向量<span class="math inline">\(a_1=(a_{11},a_{21},\cdots,a_{p1})&#39;\)</span>，<span class="math inline">\(F_1=a_{11}X_1+\cdots+a_{p1}X_p=a&#39;X\)</span>，</p>
<p><span class="math display">\[V(F_1)=a_1&#39;\Sigma a_1==a_1&#39;U\begin {bmatrix} \lambda_1 &amp; &amp; &amp; \\ &amp; \lambda_2 &amp; &amp; \\ &amp; &amp; \cdots &amp; &amp; \\ &amp; &amp; &amp; \lambda_p &amp;\end {bmatrix}U&#39;a_1\]</span></p>
<p>当且仅当<span class="math inline">\(a_1=u_1\)</span>时，即<span class="math inline">\(F_1=u_{11}X_1+\cdots+u_{p1}X_p\)</span>时，有最大的方差<span class="math inline">\(\lambda_1\)</span>。<span class="math inline">\(Var(F_1)=U_1&#39;\Sigma_x U_1=\lambda_1\)</span>。如果第一主成分的信息不够，则需要寻找第二主成分。</p>
<p><strong>第二主成分</strong></p>
<p>在约束条件<span class="math inline">\(cov(F_1,F_2)=0\)</span>下，寻找第二主成分，取线性变换，<span class="math inline">\(F_2=u_{12}X_1+\cdots+u_{p2}X_p\)</span>的方差次大。</p>
<p><span class="math display">\[cov(F_1,F_2)=cov(u_1&#39;x,u_2&#39;x)=u_2&#39;\Sigma u_1=\lambda_1 u_2&#39;u_1=0\]</span></p>
<p><span class="math display">\[Var(F_2)=U_2&#39;\Sigma_x U_2=\lambda_2\]</span></p>
<p>类推</p>
<p><span class="math display">\[F_1=u_{11}X_1+u_{21}X_2+\cdots+u_{p1}X_p\]</span></p>
<p><span class="math display">\[F_2=u_{12}X_1+u_{22}X_2+\cdots+u_{p2}X_p\]</span></p>
<p><span class="math display">\[\cdots\]</span></p>
<p><span class="math display">\[F_p=u_{1p}X_1+u_{2p}X_2+\cdots+u_{pp}X_p\]</span></p>
<p>写成矩阵形式：</p>
<p><span class="math display">\[F=U&#39;X\]</span></p>
<p><span class="math display">\[U=(u_1,\cdots,u_p)=\begin {bmatrix} u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1p} \\ u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2p} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ u_{p1} &amp; u_{p2} &amp; \cdots &amp; u_{pp} \end {bmatrix}\]</span></p>
<p><span class="math display">\[X=(X_1,X_2,\cdots,X_p)&#39;\]</span></p>
</div>
<div id="主成分的性质" class="section level2">
<h2><span class="header-section-number">12.4</span> 主成分的性质</h2>
<p>（1）<strong>均值</strong> <span class="math inline">\(E(U&#39;x)=U&#39;\mu\)</span></p>
<p>（2）<strong>方差为所有特征根之和</strong></p>
<p><span class="math display">\[\sum_{i=1}^pVar(F_i)=\lambda_1+\lambda_2+\cdots+\lambda_p=\sigma_1^2+\sigma_2^2+\cdots+\sigma_p^2\]</span>
说明主成分分析把p个随机变量的总方差分解成为p个不相关的随机变量的方差之和。协方差矩阵<span class="math inline">\(\Sigma\)</span>的对角线上的元素之和等于特征根之和。</p>
<p>（3）<strong>精度分析</strong></p>
<blockquote>
<ul>
<li>贡献率：第i个主成分的方差在全部方差中所占比重<span class="math inline">\(\lambda_i/\sum_{i=1}^p\lambda_i\)</span>，称为贡献率，体现这个主成分的综合能力的大小，即反映原来p个指标的信息的多少。</li>
<li>累积贡献率：前k个主成分共有多大的综合能力，用这个k个主成分的方差和在全部方差中所占比重<span class="math inline">\(\sum_{i=1}^k\lambda_i/\sum_{i=1}^p\lambda_i\)</span>来描述，称为累积贡献率。我们进行主成分分析的目的之一是希望用尽可能少的主成分<span class="math inline">\(F_1,F_2,\cdots,F_k(k\le p)\)</span>代替原来的p个指标。到底应该选择多少个主成分，在实际工作中，所采用主成分个数的多少取决于能够反映原来变量85%以上的信息量为依据，即当累积贡献率<span class="math inline">\(\geq85\)</span>时%的主成分的个数就足够了。最常见的情况是主成分为2到3个。</li>
</ul>
</blockquote>
<p>（3）<strong>载荷矩阵</strong></p>
<p><span class="math display">\[\begin {bmatrix} u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1m} \\ u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2m} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ u_{p1} &amp; u_{p2} &amp; \cdots &amp; u_{pm} \end {bmatrix}\]</span></p>
<p><strong>原始变量与主成分之间的相关系数</strong></p>
<p><span class="math display">\[F_j=u_{1j}x_1+u_{2j}x_2+\cdots+u_{pj}x_p j=1,2,\cdots,m,m\le p\]</span></p>
<p><span class="math display">\[F=U&#39;X UF=X\]</span></p>
<p><span class="math display">\[\begin {bmatrix} x_1 \\ x_2 \\ \vdots \\ x_p \end {bmatrix}=\begin {bmatrix} u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1p} \\ u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2p} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ u_{p1} &amp; u_{p2} &amp; \cdots &amp; u_{pp} \end {bmatrix}\begin {bmatrix} F_1 \\ F_2 \\ \vdots \\ F_p \end {bmatrix}\]</span></p>
<p><span class="math display">\[Cov(x_i,F_j)=Cov(u_{i1}F_1+u_{i2}F_2+\cdots+u_{ip}F_p,F_j)=u_{ij}\lambda_j\]</span></p>
<p><span class="math display">\[\rho(x_i,F_j)=\frac{u_{ij}\lambda_j}{\sigma_i\sqrt{\lambda_j}}=\frac{u_{ij}\sqrt{\lambda_j}}{\sigma_i}\]</span></p>
<p>可见，<span class="math inline">\(x_i\)</span>和<span class="math inline">\(F_j\)</span>的相关的密切程度取决于对应线性组合系数的大小。该相关系数又叫因子负荷量。在解释主成分的成因或是第i个变量对第k个主成分的重要性时，应当根据因子负荷量而不是变换系数u.</p>
<p><strong>原始变量被主成分的提取率：</strong>主成分的贡献率和累计贡献率度量了<span class="math inline">\(F_1,F_2,\cdots,F_m\)</span>分别从原始变量<span class="math inline">\(X_1,X_2,\cdots,X_P\)</span>中提取了多少信息。那么<span class="math inline">\(X_1,X_2, \cdots,X_P\)</span>各有多少信息分别被<span class="math inline">\(F_1,F_2,\cdots,F_m\)</span>提取？这可以用<span class="math inline">\(F_1,F_2,\cdots,F_m\)</span>分别与<span class="math inline">\(X_1, X_2,\cdots,X_P\)</span>的相关系数的平方来衡量。</p>
<p><span class="math display">\[Var(x_i)=Var(u_{i1}F_1+u_{i2}F_2+\cdots+u_{ip}F_p)\]</span></p>
<p>则</p>
<p><span class="math display">\[u_{i1}^2\lambda_1+u_{i2}^2\lambda_2+\cdots+u_{im}^2\lambda_m+\cdots+u_{ip}^2\lambda_p=\sigma_i^2\]</span></p>
<p><span class="math inline">\(u_{ij}^2\lambda_j\)</span>是<span class="math inline">\(F_j\)</span>能说明的第i 原始变量的方差。<span class="math inline">\(u_{ij}^2\lambda_j/\sigma_i^2\)</span>是<span class="math inline">\(F_j\)</span>提取的第i原始变量信息的比重。
如果我们仅仅提出了m个主成分，则第i原始变量信息的被提取率为：</p>
<p><span class="math display">\[\Omega_i=\sum_{j=1}^m\lambda_ju_{ij}^2/\sigma_i^2=\sum_{j=1}^m\rho_{ij}^2\]</span></p>
<p><strong>公共成分</strong></p>
<p>定义：如果一个主成分仅仅对某一个原始变量有作用，则称为特殊成分。如果一个主成分对所有的原始变量都起作用，则称为公共成分。</p>
</div>
<div id="主成分分析的步骤" class="section level2">
<h2><span class="header-section-number">12.5</span> 主成分分析的步骤</h2>
<p>第一步：由X的协方差阵或相关系数阵<span class="math inline">\(\Sigma\)</span>，求出其特征根，即解方程，可得特征根。</p>
<p>第二步：求出特征根所对应的特征向量<span class="math inline">\(U_1,U_2,\cdots,U_p\)</span>，</p>
<p><span class="math display">\[U_i=(u_{1i},u_{2i},\cdots,u_{pi})&#39;\]</span></p>
<p>第三步：计算累积贡献率，给出恰当的主成分个数。</p>
<p><span class="math display">\[F_i=U_i&#39;X,i=1,2,\cdots,k(k\le p)\]</span></p>
<p>第四步：计算所选出的k个主成分的得分。将原始数据的中心化值:</p>
<p><span class="math display">\[X_i^*=X_i-\bar X=(x_{1i}-\bar x_1,x_{2i}-\bar x_2,\cdots,x_{pi}-\bar x_p)&#39;\]</span></p>
<p>代入前k个主成分的表达式，分别计算出各单位k个主成分的得分，并按得分值的大小排队。</p>
<p><strong>基于协方差矩阵</strong></p>
<p>在实际问题中， X的协方差通常是未知的，样品有</p>
<p><span class="math display">\[X_1=(x_{1l},x_{2l},\cdots,x_{pl})&#39;(l=1,2,\cdots,n)\]</span></p>
<p><span class="math display">\[\hat \Sigma_x=(\frac{1}{n-1}\sum_{l=1}^n(x_{ij}-\bar x_i)(x_{jl}-\bar x_j))_{p\times p}\]</span></p>
<p><strong>基于相关系数矩阵</strong></p>
<p>如果变量有不同的量纲， 变量水平差异很大，应该基于相关系数矩阵进行主成分分析。不同的是计算得分时应采用标准化后的数据。</p>
</div>
<div id="主成分的应用与回归" class="section level2">
<h2><span class="header-section-number">12.6</span> 主成分的应用与回归</h2>
<p>（1）主成分分析能降低所研究的数据空间的维数。即用研究m维的Y空间代替p维的X空间(<span class="math inline">\(m&lt;p\)</span>)，而低维的Y空间代替高维的x空间所损失的信息很少。即使只有一个主成分<span class="math inline">\(Y_1\)</span>(即m＝1)时，这个<span class="math inline">\(Y_1\)</span>仍是使用全部X变量(p个)得到的。在所选的前m个主成分中，如果某个<span class="math inline">\(X_i\)</span>的系数全部近似于零的话，就可以把这个<span class="math inline">\(X_i\)</span>删除，这也是一种删除多余变量的方法。</p>
<p>（2）多维数据的一种图形表示方法。多元统计研究的问题大都多于3个变量，要把研究的问题用图形表示出来是不可能的。然而，经过主成分分析后，我们可以选取前两个主成分或其中某两个主成分，根据主成分的得分，画出n个样品在二维平面上的分布情况，由图形可直观地看出各样品在主分量中的地位。</p>
<p>（3）用主成分分析法构造回归模型。即把各主成分作为新自变量代替原来的自变量做回归分析。</p>
<p><strong>主成分回归方法</strong></p>
<p><span class="math display">\[F_1=u_{11}X_1+u_{21}X_2+\cdots+u_{p1}X_p\]</span>
<span class="math display">\[F_2=u_{12}X_1+u_{22}X_2+\cdots+u_{p2}X_p\]</span></p>
<p><span class="math display">\[\cdots\]</span></p>
<p><span class="math display">\[F_p=u_{1p}X_1+u_{2p}X_2+\cdots+u_{pp}X_p\]</span></p>
<p><span class="math display">\[Y_i^*=\gamma_1F_{11}+\gamma_2F_{12}+\cdots+\gamma_mF_{1m}+\varepsilon_i\]</span></p>
<p><span class="math display">\[\sum_{i=1}^n[Y_i^*-\gamma_1F_{11}-\gamma_2F_{12}-\cdots-\gamma_mF_{1m}]^2=min\]</span></p>
<p>原始数据观测矩阵</p>
<p><span class="math display">\[X_0=\begin {bmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \\ x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} \end {bmatrix}\]</span></p>
<p>主成分系数矩阵</p>
<p><span class="math display">\[U=(u_1,\cdots,u_p)=\begin {bmatrix} u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1p} \\ u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2p} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ u_{p1} &amp; u_{p2} &amp; \cdots &amp; u_{pp} \end {bmatrix}\]</span></p>
<p>主成分得分矩阵</p>
<p><span class="math inline">\(\begin {bmatrix} F_{11} &amp; F_{12} &amp; \cdots &amp; F_{1p} \\ F_{21} &amp; F_{22} &amp; \cdots &amp; F_{2p} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ F_{n1} &amp; F_{n2} &amp; \cdots &amp; F_{np} \end {bmatrix}\)</span></p>
<p><span class="math inline">\(F=X_0U\)</span></p>
<p><strong>主成分分析的一些注意事项</strong></p>
<p>主成分分析依赖于原始变量，也只能反映原始变量的信息。所以原始变量的选择很重要。
如果原始变量本质上独立，那么降维就可能失败，这是因为很难把很多独立变量用少数综合的变量概括。数据越相关，降维效果就越好。
分析结果并不一定会有清楚的解释。这与问题的性质，选取的原始变量以及数据的质量等都有关系。</p>
<p><strong>基于相关系数矩阵还是基于协方差矩阵做主成分分析？</strong></p>
<p>有时基于相关系数矩阵和基于协方差矩阵求出的主成分会有很大不同，且两者之间不存在简单的线性关系。
一般而言，当分析中所选择的经济变量具有不同的量纲，变量水平差异很大，应考虑将数据标准化，选择基于相关系数矩阵的主成分分析。对同度量或是取值范围在同量级的数据，选择基于协方差矩阵的主成分分析。</p>
<p><strong>选择几个主成分？</strong></p>
<p>主成分分析的目的是简化变量，一般情况下主成分的个数应该小于原始变量的个数。关于保留几个主成分，应该权衡主成分个数和保留的信息。</p>
<p><strong>如何解释主成分所包含的经济意义？</strong></p>
<p>主成分分析不要求数据来自于正态总体。一般认为当原始数据大部分变量的相关系数都小于0.3时，运用主成分分析的效果不显著。</p>
</div>
<div id="主成分分析的r语言实现" class="section level2">
<h2><span class="header-section-number">12.7</span> 主成分分析的R语言实现</h2>
<p>主成分分析的函数本篇介绍的主要有两个。一个是princomp，一个是psych里的principal。</p>
<pre><code>princomp(x,cor=FALSE,scores=TRUE)</code></pre>
<p>x为主成分分析数据集，cor=TRUE和FALSE分别代表是基于相关系数矩阵计算还是协方差矩阵计算。scores则代表是否存储主成分得分。</p>
<pre><code>principal(x,nfactors=2,rotate=&quot;varimax&quot;,scores=T,covar=F)</code></pre>
<p>x为主成分分析数据集，nfactors为主成分个数，rotate表示旋转方式（一般选方差最大，保证互不相关），scores则代表是否存储主成分得分，covar=TRUE和FALSE分别代表是基于协方差矩阵计算还是相关系数矩阵计算。</p>
<p>这回用的数据是2006年城市统计年鉴285个地级市的经济人口数据，探究gdp与人口之间的关系。先做一个相关系数可视化。发现人口因子之间相互影响作用很高。</p>
<p><img src="bookdown_files/figure-html/unnamed-chunk-82-1.png" width="100%" height="40%" /></p>
<p>于是先对人口的几个因子进行降维和主成分分析，中途发现第三产业从业人数（third)加入会使得系数矩阵不正定，后面就删除了第三产业从业人数(third)。分别用不同方式进行主成分分析结果。</p>
<ul>
<li>princomp结果（基于协方差矩阵）</li>
</ul>
<p>碎石图</p>
<p><img src="bookdown_files/figure-html/unnamed-chunk-83-1.png" width="100%" height="40%" /></p>
<p>结果</p>
<p><img src="fig/fig37.jpg" width="100%" height="35%" /></p>
<p>主成分得分图</p>
<p><img src="bookdown_files/figure-html/unnamed-chunk-85-1.png" width="100%" height="40%" /></p>
<ul>
<li>princomp结果（基于相关系数矩阵）</li>
</ul>
<p>碎石图</p>
<p><img src="bookdown_files/figure-html/unnamed-chunk-86-1.png" width="100%" height="40%" /></p>
<p>结果</p>
<p><img src="fig/fig38.jpg" width="100%" height="35%" /></p>
<p>主成分得分图</p>
<p><img src="bookdown_files/figure-html/unnamed-chunk-88-1.png" width="100%" height="40%" /></p>
<ul>
<li>principal结果</li>
</ul>
<p>碎石图</p>
<p><img src="bookdown_files/figure-html/unnamed-chunk-89-1.png" width="100%" height="40%" /></p>
<pre><code>## Parallel analysis suggests that the number of factors =  NA  and the number of components =  2</code></pre>
<p>因子关系图</p>
<p><img src="bookdown_files/figure-html/unnamed-chunk-90-1.png" width="100%" height="40%" /></p>
<p>主成分得分图</p>
<p><img src="bookdown_files/figure-html/unnamed-chunk-91-1.png" width="100%" height="40%" /></p>
<p>碎石图表示的是曲线与纵坐标1交点的横坐标即为主成分个数，而主成分得分荷图是将原始数据的坐标映射在主成分分析的坐标上，事实上可以根据主成分得分在不同象限对原始数据进行分类，在本篇的样例数据里其实就是可以通过人口生成的几个主成分对中国地级市进行分类，可以区分出是在第一主成分得分高，第二主成分得分低的城市，亦或是其他排列组合的分类结果。关于这种可视化图具体如何解释。可以参照如下的文章。</p>
<blockquote>
<p><a href="http://www.cnblogs.com/SCUJIN/p/5965946.html" class="uri">http://www.cnblogs.com/SCUJIN/p/5965946.html</a></p>
</blockquote>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="discriminant.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="fa.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/yihui/bookdown-chinese/edit/master/12-pca.Rmd",
"text": "编辑"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown.pdf", "bookdown.epub"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
